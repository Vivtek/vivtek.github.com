<html>
<head>
<title>Keyword spam</title>
<style>p, li, td {
font-family: arial, sans-serif;
}
p.smtitle {
margin-left:0px;background-color:#eeeeee;font-weight:bold;
}
.sidemenu p {
font-size:small;
margin-top:0px;
margin-bottom:2px;
margin-left:10px;
}
.title {
font-family: arial, sans-serif;
font-weight: bold;
font-size:x-large;
color:black;
background-color:#eeeeee;
}
.subtitle {
font-family: arial, sans-serif;
font-size:small;
}
.t2 {
font-family: arial, sans-serif;
font-weight: bold;
font-size:large;
color:black;
background-color:#eeeeee;
}
.st2 {
font-family: arial, sans-serif;
font-size:x-small;
}
.border {
border: 1px solid #336600;
}
.content {
}
.code {
  margin: .5em 1em;
  padding: 0.5em;
  border: 1px dashed #94bd8d;
  color: Black;
  background-color: #eff7ef;
  overflow: auto;
}
.synComment    { color: #0000FF }
.synConstant   { color: #FF00FF }
.synIdentifier { color: #008B8B }
.synStatement  { color: #A52A2A ; font-weight: bold }
.synPreProc    { color: #A020F0 }
.synType       { color: #2E8B57 ; font-weight: bold }
.synSpecial    { color: #6A5ACD }
.synUnderlined { color: #000000 ; text-decoration: underline }
.synError      { color: #FFFFFF ; background: #FF0000 none }
.synTodo       { color: #0000FF ; background: #FFFF00 none }
.linenum       { color: #222222 ; background: #EEEEEE none }
</style>
</head>
<body>
<table width="100%">
<tr>
<td valign="top" width="150px"><div class="sidebar">
<div class="border">
<div class="sidemenu">
<p class="smtitle">vivtek</p>
<p>[ <a href=/>home</a> ]</p>
<p>[ <a href=/blog/>blog</a> ]</p>
<p>[ <a href=/recent.html>recent</a> ]</p>
<p>[ <a href=/projects/>programming</a> ]</p>
<p>[ <a href=/translation/>translation</a> ]</p>
<p>[ <a href=/fiction/>fiction</a> ]</p>
<p>[ <a href=/contact.html>contact</a> ]</p>
</div>

<div class="sidemenu">
<p class="smtitle">blog</p>
<p>[ <a href="keywords.html">keywords</a> ]</p>
<p class="smtitle">blogger</p>
<p>[ <a href="http://semantic-programming.blogspot.com/">semprog</a> ]</p>
<p>[ <a href="http://startup-ideas.blogspot.com/">startups</a> ]</p>
<p>[ <a href="http://orgaprop.blogspot.hu/">politics</a> ]</p>
</div>

<hr />
<script type="text/javascript"><!--
google_ad_client = "pub-7508846022405297";
google_ad_width = 120;
google_ad_height = 600;
google_ad_format = "120x600_as";
google_ad_type = "text";
google_ad_channel = "";
//--></script>
<script type="text/javascript"
  src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>

</div>

</div>
</td>
<td valign="top"><div class="content">

<div class="title">Keyword spam</div>
<div class="st2"></div>
<hr>
<table>
<tr>
<td><div class="title"><a href="xrumer_and_you.html">XRUMER and you</a></div>
<div class="st2">2006-12-17 <a href="keyword_spam.html">spam</a> <a href="keyword_xrumer.html">xrumer</a></div><br>
(coff)
</p><p>
Need overview about XRumer software?<br>
I'm seeking for any information about <b>XRUMER program</b>. <br>Can you help me? Or give me a link to the official site with this autosubmitter.
</p><p>
There.  Now let's wait a week for Google to index this, and see what the log drags in.  Thank you very much, and I now return you to your regularly
scheduled programming.
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="the_reanimated_zombie_corpse_of_despammed_com.html">The reanimated zombie corpse of Despammed.com</a></div>
<div class="st2">2006-12-27 <a href="keyword_despammed.html">despammed</a> <a href="keyword_spam.html">spam</a></div><br>
Once, many years ago, I did a foolish thing.  I wrote a quick little spam filtration forwarder and opened it up to the public.  As far as I can tell,
I was the first person to have done so.
</p><p>
The year was 1999, and the Boom was in full swing.  My plan was simple: (1) write a free online service, (2) ???, and (3) profit!!!  As you no doubt
can surmise, #2 never really happened, let alone #3.  But from 1999 to sometime in 2005, I kept that thing running, through three servers, four household
moves, and a growth in userbase from two to a few thousand (if I recall correctly).
</p><p>
Then: the server died.  I mean, it died suddenly and irretrievably, and I (never much of a stickler for formalities) had not backed it up.  Ever.  I'd
simply moved it from place to place while <i>intending fully</i> to back it up, and all the old machines were broken into their constituent materials
by that time.  As I was going through some
serious financial woes, and as my wife and I had found that our son has a kidney disorder, my priorities were clear.  Despammed.com was superfluous.
</p><p>
But it nagged at me.  Despammed.com lived on in my heart, even though its DNS entries pointed to an IP now occupied by some calendar service thing.
(Which was weird.)  And then I found a not-too-dusty copy of the HTML.  And last month I found relatively good copies of the filtration software.  I still
don't have the user database or the administration/registration code or the statistics or the filter databases or, really, anything.  But what the heck.
I <a href="http://www.despammed.com">put it back online anyway</a>.  I'm nearly positive I'm going to live to regret it.
</p><p>
But I still feel a warm holiday glow.  I'm giving back to the community again.  Merry Christmas to all of you!  And if Despammed.com breaks into your
house wanting to eat your brains, remember: a headshot is mandatory.
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="forum_spam.html">Forum spam</a></div>
<div class="st2">2006-12-31 <a href="keyword_spam.html">spam</a></div><br>
Over at Toonbots, I have a <a href="http://www.vivtek.com/toonbots/discuss.pl">forum</a>, based on ancient
but reliable Perl code.  For many years, that forum has been a quiet backwater
of the Net where I chat on various topics with those of my friends who enjoy
that facet of my personality responsible for the engendering of Toonbots.
</p><p>
But lately, something extremely irritating has happened.  The forum has become
the target of forum spammers.  Their spam rarely even formats correctly, since
the forum code is so old and weird.  But that doesn't stop three or four of
them from posting every day, and I have to delete it all by hand, or relinquish
the forum to utter uselessness.
</p><p>
Oddly, the <a href="http://www.vivtek.com/wftk/discuss.pl">wftk forum</a> is utterly unaffected by all this.
Since the trouble started when I started properly indexing the forum archives,
I suspect the archives are acting as a Google magnet for various topics.
But I'm not sure yet.
</p><p>
The modus operandi of forum spammers is different from real posters, according
to the logs; typically the forum spammer hits the site for the first time in
the forum archives, then posts within a few seconds.  Real posters actually
read the site first.  So I <i>could</i> filter based on that behavior.  But
I'm going to study the issue for a while, see if I can detect any other
useful patterns.  It's a serious problem, and a growing one; email spamming
is experiencing diminishing returns now, since fewer people read email thanks
to spam.  So forum spamming is a logical progression.
</p><p>
Jerks.
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="despamming_the_toonbots_forum.html">Despamming the Toonbots forum</a></div>
<div class="st2">2007-02-04 <a href="keyword_spam.html">spam</a></div><br>
I just wrote a rather effective spam eliminator for my WebBBS forum at Toonbots, and sort of "live blogged" the process as I went.
The result is a <a href="/projects/forum_despammer/">rather attractive little document</a>.  I feel virtuous again tonight.
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="xrumer_s_popularity_continues_unabated.html">XRUMER's popularity continues unabated</a></div>
<div class="st2">2007-02-05 <a href="keyword_spam.html">spam</a> <a href="keyword_xrumer.html">xrumer</a></div><br>
When I initially posted the XRUMER and you post, I thought that XRUMER
probably used the text I posted (which I had found on a forum I frequent)
to identify spammable fora -- those for which moderation is not performed.
</p><p>
Later, I came across the theory that this post was in fact some pretty
clever viral marketing.  By pretending to ask the forum's members about
XRUMER, the XRUMER marketer could induce at least some people to search on
it and link it, causing Google to rate it highly without actually themselves
spamming.  Neat.
</p><p>
But for whatever reason, my post caused Google to rate <i>me</i> third on
searches on the term XRUMER -- and instead of XRUMER, I'm seeing a lot of
traffic from people obviously interested in <i>stopping</i> it.
</p><p>
As am I.
</p><p>
But I don't have access to a forum affected by XRUMER (or at least, I can't
tell for sure that I do.)  My own Toonbots forum is an extremely low-traffic
venue running on antiquated WebBBS code.  I get spam there, and this week
<a href="/projects/forum_despammer/">managed to block it all</a> (so far), but my problem
is decidedly minor.
</p><p>
I can only assume that if you're reading this, you have a major forum spam
problem.  If this is the case, I need your help.  I'd like to try out some
ideas about forum despamming -- building on the working concepts in my own
low-traffic venue.  But to try these ideas out, <b>I'd need access to a forum.
Your forum,</b> if you're interested.  And that essentially means access to the
underlying storage (whether filesystem or database), a way to run Perl on your
box, and access to the Web access logs in real time.
</p><p>
Depending on your own traffic patterns, the access logs can provide a great
deal of information about whether a post is legitimate or not.  Of course,
you can also make a lot of valid judgments based on the post content, but I
hesitate to block on things like "too many links," as satisfying as that
heavy-handed approach may be.  Legitimate users can often have legitimate
reasons to post lots of links.  Granted, they're generally not about Cialis
or mortgages or hot xxxxxxx Asian lesbian pr0n, but still -- any interference
with your actual users is something you want to avoid at all costs.  I regard
information about post content to be one factor in a good, well-rounded
spam elimination strategy.
</p><p>
Traffic analysis correlated with forum activity can be a powerful tool, and
in my own case it's working 100%, with no examination of content at all, but
my traffic is so low that I can't judge how complete a strategy it might be.
If you add your forum to the mix, I can improve the techniques.
</p><p>
So anyway, all you desperate forum admins with XRUMER problems -- if you want
me to give it a shot, drop me a line.  I'm working for free and during an
initial phase my scripting can simply recommend post deletion instead of making
any automated changes itself.  Interested?  <a href="mailto:michael@despammed.com?subject=XRUMER%20despamming">Tell me.</a>
</p><p>
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="xrumer_-_they_re_back!.html">XRumer - they're back!</a></div>
<div class="st2">2007-04-06 <a href="keyword_xrumer.html">xrumer</a> <a href="keyword_spam.html">spam</a></div><br>
So hey, kids, I'm still alive, and now posting from the lovely Caribbean island of Puerto Rico for the foreseeable future.
</p><p>
After the move, and after some confusion on the part of the cable company involving <i>losing my order</i>, I have blessed, blessed broadband
again, without having to cadge the neighbors' WiFi from the rooftop terrace, which would be a great place to work were it not for the tropical
proximity of a horrible huge ball of blazing nuclear explosion hanging over my head, plus the necessity of placing the laptop in a
precarious position on the railing, four floors above concrete, to get good signal.
</p><p>
But now things are good again, and I have 9000 emails to go through (yes, as a guy with a spam filter, I should probably be filtering my spam, but,
well, it's a long story and <i>look, shiny thing!</i>).  And lo! within those 9000 mails were two from hapless forum operators who are getting fed
up with manual despamming.
</p><p>
So sure, I'll be seeing what I can do in that regard, but it piqued my interest in forum spam again.  And so I checked my logs for instances of
XRumer, and wow -- somebody actually <a href="http://kenya.rcbowen.com/talk/viewtopic.php?id=8545">linked my XRumer blog keyword</a> in response to
... a new instance of the XRumer forum bomb.  Dated April 5, as
it so happens.  This one contains the novel text "Also, do you know when XRumer 4.0 Platinum Edition will be released?" and it's posted by AlexMrly.
Google either the phrase or the name, and you'll see a whole lot of forum spam.  Hey, XRumer guys -- thanks!  What we all want is more forum spam!
</p><p>
Now I have that off my chest.  I'm going to reiterate my offer to anybody listening -- I'm going to see what I can do to combat forum spam around
the world, and I'm not charging anything for it.  So far, I'm just in it for the interest, just like email spam in 1999.  Get in touch.  I'll be here.
Well -- I might actually be at the beach.  But I'll be back soon.
</p><p>
Sorry that this post isn't really all that programming-oriented.  I hope to be making that right, in the next couple of days.  Blocking XRumer is
fun, and so easy even a child could do it!  No, seriously: if you want to help me stop XRumer, all I need is your data.
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="modbot_google_counter_and_the_spam_archive.html">modbot, google counter, and the spam archive</a></div>
<div class="st2">2007-05-07 <a href="keyword_spam.html">spam</a> <a href="keyword_modbot.html">modbot</a> <a href="keyword_google_count.html">google_count</a></div><br>
Three related things today.  First, the scripts I've been putting together for forum spam blocking have kind of coalesced into a "modbot".  This
program attempts to automate the tasks performed by human moderators and could technically be placed into <i>any</i> Web spam moderation situation.
It is currently running happily in an Eboard 4.0 installation and blocking roughly 93% of spam, while still allowing anonymous posting to that forum.
I'll be packaging it up for distribution in the public domain.  Watch this space for further details -- one of the more fascinating notions I've
had is to enable it to receive moderation emails from Blogger and thus automate the comment moderation process there.
</p><p>
One of the rules/tools used by the modbot is to count Google hits for the numeric IP of an untrusted poster.  Turns out that HTTP proxies have a
real proclivity for getting indexed.  A lot.  Legitimate IPs, not so much.  I wrote a little online tool to call Google to get these counts; the
<a href="/google_count.html">tool is here</a> and the <a href="/projects/forum_despammer/google_count.html">write-up of the code is here</a>.  It's currently blocking about
40% of spam (I don't have good statistics analysis in place yet, so that's very approximate.)
</p><p>
Finally, as a spinoff of this project, I've started a spam archive.  There's nothing to present yet, but I hope to start doing some interesting
analysis, and most specifically a searchable database -- along with a searchable database of spamvertised sites.  That ought to overlap with
the sites spamvertised by email spam as well, and that's going to be an interesting thing to look at.  We'll see.
</p><p>
I've stumbled onto a spam link network of staggering extent in the course of examining forum spam.  A spammer has a site somewhere, and then spamvertises
it.  But then some of the spam starts to link to other forum spam, which in turn links to the site.  Some sites auto-forward to other sites using
obscured Javascript (I haven't figured out just why, yet; if you have a rationale, I'd be happy to hear it.)  Anyway, after that goes on for a while,
there's a huge resulting network of vulnerable fora linking to other vulnerable fora.  There is a true treasure trove of information available to
the interested party.  Which would, of course, be me.  I will <i>definitely</i> be following up on that and posting on it.
</p><p>
Anyway, it's been nice talking to you.  Back to work!
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="some_initial_forum_spam_statistics.html">Some initial forum spam statistics</a></div>
<div class="st2">2007-05-13 <a href="keyword_spam.html">spam</a> <a href="keyword_forumspam.html">forumspam</a></div><br>
Now that I've been collecting spam from actual fora for a little while,
I have some initial statistics and musings.
</p><p>
I've collected spam from one eBoard 4.0 forum since May 5; it is now
May 13.  The spam filters I'm using are blocking about 93% of the postings,
making the moderation burden manageable for that forum.  In those 8 days
I have collected 1,235 spam samples.  That's 150 spams a day, from a fairly
obscure forum; in retrospect, even though the actual log activity seems
low, this is a lot of spam.
</p><p>
Those 1,235 spam samples link to a total of 10,795 links.  I haven't yet
built analysis machinery to get much farther than that; I've mostly been just
looking at the links, retrieving the pages, and musing about how all that
might be automated in an interesting and useful way.
</p><p>
Some tidbits:
</p><p>
Some of the spam links point to actual sites being advertised.  I don't yet
have a feel for many links point to sites <i>other</i> than those actually
advertised, but there are some interesting commonalities.  For instance, there
are a <i>lot</i> of pages placed onto vulnerable fora and other venues which
simply link to other pages.  In some cases, it's easy to tell why: Google
spamming and simply a way to counter attempts to block posts which link
to particular URLs.
</p><p>
I have a separate notion to find and track those vulnerable sites, and to
attempt to mine them for further information on these spam networks.
</p><p>
Bugzilla, oddly enough, seems to have such a vulnerability.  (Can you call this
a vulnerability?)  There are links to pages stored as attachments to bug
reports.  Those attachments are (naturally enough) not subject to any content
restrictions.  Unfortunately, that means you can put any Javascript into them
at all.
</p><p>
I haven't yet found actual malicious Javascript being spammed to fora.  What
I <i>have</i> found is obscured Javascript which modifies document.location to
force a page forward to another site.  I consider that semimalicious, and my
initial goal is to find a way to detect that with some sort of automatic
analysis, and block posts based solely on the basis of link to that sort of
page.
</p><p>
I figure it's only a matter of time, though, before I find some actual
malicious Javascript which will attempt to rootkit my machine with keyboard
loggers to steal my bank accounts.  That's pretty cool, actually, so I'm
watching the spam traps with bated breath.
</p><p>
One spam has a huge number of links to different domains, all of which resolve
to the same IP.  That's an interesting feature.  I'm not sure how to track it
yet.  What I really want to do is some kind of <i>generic analysis framework</i>,
but I don't have a good picture of what that framework would look like, or
indeed precisely what it is that I expect it to do.
</p><p>
It seems that what I want to do is to build a kind of task list for an incoming
event.  That task list would consist of a certain (small) number of analysis
steps which themselves generate new analysis events.  Each step is a test.
The results of the tests are cached, so that all possible duplicated effort
is avoided, but also so that relationships such as "these spam efforts share
an IP" can be found.
</p><p>
There's a certain exponential explosion involved, it seems at times.  But there
are also patterns which could cut down on the amount of work done.  Of those
10,795 links I have so far (oops, in the time it's taken to write this
much, two more spams have arrived, so I now have 10,886 links to analyze) --
of those 10,886 links I have, many of them are hosted at
<something>.007ihost.com -- 2,804 of them, as a matter of fact.  It will be
very interesting to analyze the spam pattern there, by the way.  Are all of
these from the same spammer?  Same IP?  (Bet not.)  But more germane to the
point I was making, eliminating those URLs from separate analysis will cut out
20% of the analysis effort.
</p><p>
Well, anyway, this is just a little talking out loud while I muse about how
to automate all this analysis.  Eventually I'll get down to posting graphs
of some sort.  That will be fun.  The other thing, of course, is some way
to ask about a URL, "Is this URL a spam indicator?"  I hope it will also
cross-fertilize with <a href="http://www.despammed.com">Despammed.com</a>.  Wish me
luck.
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="online_forensics.html">Online forensics</a></div>
<div class="st2">2008-07-16 <a href="keyword_spam.html">spam</a> <a href="keyword_internet_sleuthing.html">internet_sleuthing</a></div><br>
I've always had a soft spot for good explanations of Internet sleuthing for
fun and profit, and <a href="http://justinsomnia.org/2007/08/search-engine-marketeers-are-the-new-script-kiddies/">here's a dandy example</a>.
</p><p>
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="cool_spammed_malware_trail.html">Cool spammed malware trail</a></div>
<div class="st2">2008-07-26 <a href="keyword_javascript_obfuscation.html">javascript_obfuscation</a> <a href="keyword_spam.html">spam</a> <a href="keyword_sleuthing.html">sleuthing</a></div><br>
I got a spam today saying the Beijing Olympics had been cancelled, so I was all "O hai, Botnet, I can has spamtrail?"  (Because I hear the Russians are using fake news headlines to induce people to open the mail now.  And part of this trail goes through Russia, as we'll see.)
</p><p>
The whole story (well, as much as I've followed and written down so far) <a href="/projects/despammed/bollettinogiuridicosanitario.html">is over here</a> because it is really detailed.  But it's fun so far, because not only is the main injection page obfuscated, it appears to be <i>encrypted</i> and the decryption code is itself obfuscated and located on a different server.  In Russia.
</p><p>
So far, it's been instructive, as always when one unravels these threads.  More later.
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="botnet_spam_flood.html">My God, it's full of stars! Botnet spam flood</a></div>
<div class="st2">2008-08-01 <a href="keyword_spam.html">spam</a> <a href="keyword_botnet.html">botnet</a> <a href="keyword_javascript.html">javascript</a></div><br>
So I got halfway through analysis of my <a href="/projects/monkeywrench/cases/case_1/">first Javascript obfuscation discovered via spam</a>, when <a href="/projects/monkeywrench/cases/case_2/">another</a> came in, and then <a href="/projects/monkeywrench/cases/case_3/">another</a>!  And then I realized -- these were sent from botnet-controlled mailers that were slipping past my no-DSL filters at Despammed.  So how many were getting blocked?
</p><p>
Turns out, a lot.  Like, a <i>lot</i>.  So I'm going to have plenty of grist for this mill -- and the very fascinating thing is that it sure looks like there is a change in tactics each day.  So I'm going to try to go back through older instances and hope that people haven't fixed their servers yet for some, and I'm going to put up some early warnings to tell me about new ones -- but this is truly, truly fun.
</p><p>
Each of these mails has a faux news headline: "Michael Vick escapes from Federal jail", or "Beijing Olympics canceled", the one that first drew my attention.  Then the body of the mail has a <i>different</i> headline, and a link.
</p><p>
Turns out that different headline is drawn from the same list.  So I can check the Despammed.com spam archive (1.2 million spam emails on file at the moment) for other emails with that subject.  And so on.  This should allow me to build a database of subjects really, really easily.  And then I can simply scan for those subjects to find new instances.  If they select their headlines randomly (and I have no reason to believe they don't) this should allow me to find all their headlines and keep up with new ones at the same time.  Fun!
</p><p>
Once I've got that coded, I'll post a <a href="/projects/despammed/stormspam/">database page in real time</a>. [Updated to include link.]  That will be even more fun.  And <i>then</i> I can resume the de-obfuscation effort.  Actually, I've dusted off some old project idea notes and started work on the <a href="/projects/monkeywrench/">monkeywrench</a> to help me organize this stuff.
</p><p>
Note to anybody interested: the design philosophy of the monkeywrench is essentially a <a href="http://cogsci.indiana.edu">Hofstadter parallel terraced scan</a>.  But operated by a human (for now) in a <a href="/wftk/">workflow paradigm</a>.  I can sloooowly start to feel the various bits of my life coming together.
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="storm_guys_lamer_today.html">Storm botnet standards slipping</a></div>
<div class="st2">2008-08-03 <a href="keyword_botnet.html">botnet</a> <a href="keyword_spam.html">spam</a></div><br>
Over the past couple of days as I datamined the <a href="http://www.despammed.com/">Despammed</a> spam archives for Storm botnet spam, I've grown to really enjoy their madcap subjects (latest <a href="/projects/despammed/stormspam.html">here</a>).  But today?
</p><p>
Guys!  "Obama bribing countrymen" or "McCain picks Osama bin Laden as VP" are hilarious!  But "Video News"?  "Top stories"?  Come on!  If you're going to hijack a million people's machines to spam us all, the least you can do is to continue to be entertaining about it.  This?  This is beneath you.
<br>
</td>
</tr>
</table>

</div></td></td></table>

<br><br><br><br>
    <center><img src="/images/black.gif" height=1 width=300><br>
    <Font Size="-1"><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</Font>
</center>


</body>
</html>
