<html>
<head>
<title>Keyword xrumer</title>
<style>p, li, td {
font-family: arial, sans-serif;
}
p.smtitle {
margin-left:0px;background-color:#eeeeee;font-weight:bold;
}
.sidemenu p {
font-size:small;
margin-top:0px;
margin-bottom:2px;
margin-left:10px;
}
.title {
font-family: arial, sans-serif;
font-weight: bold;
font-size:x-large;
color:black;
background-color:#eeeeee;
}
.subtitle {
font-family: arial, sans-serif;
font-size:small;
}
.t2 {
font-family: arial, sans-serif;
font-weight: bold;
font-size:large;
color:black;
background-color:#eeeeee;
}
.st2 {
font-family: arial, sans-serif;
font-size:x-small;
}
.border {
border: 1px solid #336600;
}
.content {
}
.code {
  margin: .5em 1em;
  padding: 0.5em;
  border: 1px dashed #94bd8d;
  color: Black;
  background-color: #eff7ef;
  overflow: auto;
}
.synComment    { color: #0000FF }
.synConstant   { color: #FF00FF }
.synIdentifier { color: #008B8B }
.synStatement  { color: #A52A2A ; font-weight: bold }
.synPreProc    { color: #A020F0 }
.synType       { color: #2E8B57 ; font-weight: bold }
.synSpecial    { color: #6A5ACD }
.synUnderlined { color: #000000 ; text-decoration: underline }
.synError      { color: #FFFFFF ; background: #FF0000 none }
.synTodo       { color: #0000FF ; background: #FFFF00 none }
.linenum       { color: #222222 ; background: #EEEEEE none }
</style>
</head>
<body>
<table width="100%">
<tr>
<td valign="top" width="150px"><div class="sidebar">
<div class="border">
<div class="sidemenu">
<p class="smtitle">vivtek</p>
<p>[ <a href=/>home</a> ]</p>
<p>[ <a href=/blog/>blog</a> ]</p>
<p>[ <a href=/recent.html>recent</a> ]</p>
<p>[ <a href=/projects/>programming</a> ]</p>
<p>[ <a href=/translation/>translation</a> ]</p>
<p>[ <a href=/fiction/>fiction</a> ]</p>
<p>[ <a href=/contact.html>contact</a> ]</p>
</div>

<div class="sidemenu">
<p class="smtitle">blog</p>
<p>[ <a href="keywords.html">keywords</a> ]</p>
<p class="smtitle">blogger</p>
<p>[ <a href="http://semantic-programming.blogspot.com/">semprog</a> ]</p>
<p>[ <a href="http://startup-ideas.blogspot.com/">startups</a> ]</p>
<p>[ <a href="http://orgaprop.blogspot.hu/">politics</a> ]</p>
</div>

<hr />
<script type="text/javascript"><!--
google_ad_client = "pub-7508846022405297";
google_ad_width = 120;
google_ad_height = 600;
google_ad_format = "120x600_as";
google_ad_type = "text";
google_ad_channel = "";
//--></script>
<script type="text/javascript"
  src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script>

</div>

</div>
</td>
<td valign="top"><div class="content">

<div class="title">Keyword xrumer</div>
<div class="st2"></div>
<hr>
<table>
<tr>
<td><div class="title"><a href="xrumer_and_you.html">XRUMER and you</a></div>
<div class="st2">2006-12-17 <a href="keyword_spam.html">spam</a> <a href="keyword_xrumer.html">xrumer</a></div><br>
(coff)
</p><p>
Need overview about XRumer software?<br>
I'm seeking for any information about <b>XRUMER program</b>. <br>Can you help me? Or give me a link to the official site with this autosubmitter.
</p><p>
There.  Now let's wait a week for Google to index this, and see what the log drags in.  Thank you very much, and I now return you to your regularly
scheduled programming.
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="xrumer_s_popularity_continues_unabated.html">XRUMER's popularity continues unabated</a></div>
<div class="st2">2007-02-05 <a href="keyword_spam.html">spam</a> <a href="keyword_xrumer.html">xrumer</a></div><br>
When I initially posted the XRUMER and you post, I thought that XRUMER
probably used the text I posted (which I had found on a forum I frequent)
to identify spammable fora -- those for which moderation is not performed.
</p><p>
Later, I came across the theory that this post was in fact some pretty
clever viral marketing.  By pretending to ask the forum's members about
XRUMER, the XRUMER marketer could induce at least some people to search on
it and link it, causing Google to rate it highly without actually themselves
spamming.  Neat.
</p><p>
But for whatever reason, my post caused Google to rate <i>me</i> third on
searches on the term XRUMER -- and instead of XRUMER, I'm seeing a lot of
traffic from people obviously interested in <i>stopping</i> it.
</p><p>
As am I.
</p><p>
But I don't have access to a forum affected by XRUMER (or at least, I can't
tell for sure that I do.)  My own Toonbots forum is an extremely low-traffic
venue running on antiquated WebBBS code.  I get spam there, and this week
<a href="/projects/forum_despammer/">managed to block it all</a> (so far), but my problem
is decidedly minor.
</p><p>
I can only assume that if you're reading this, you have a major forum spam
problem.  If this is the case, I need your help.  I'd like to try out some
ideas about forum despamming -- building on the working concepts in my own
low-traffic venue.  But to try these ideas out, <b>I'd need access to a forum.
Your forum,</b> if you're interested.  And that essentially means access to the
underlying storage (whether filesystem or database), a way to run Perl on your
box, and access to the Web access logs in real time.
</p><p>
Depending on your own traffic patterns, the access logs can provide a great
deal of information about whether a post is legitimate or not.  Of course,
you can also make a lot of valid judgments based on the post content, but I
hesitate to block on things like "too many links," as satisfying as that
heavy-handed approach may be.  Legitimate users can often have legitimate
reasons to post lots of links.  Granted, they're generally not about Cialis
or mortgages or hot xxxxxxx Asian lesbian pr0n, but still -- any interference
with your actual users is something you want to avoid at all costs.  I regard
information about post content to be one factor in a good, well-rounded
spam elimination strategy.
</p><p>
Traffic analysis correlated with forum activity can be a powerful tool, and
in my own case it's working 100%, with no examination of content at all, but
my traffic is so low that I can't judge how complete a strategy it might be.
If you add your forum to the mix, I can improve the techniques.
</p><p>
So anyway, all you desperate forum admins with XRUMER problems -- if you want
me to give it a shot, drop me a line.  I'm working for free and during an
initial phase my scripting can simply recommend post deletion instead of making
any automated changes itself.  Interested?  <a href="mailto:michael@despammed.com?subject=XRUMER%20despamming">Tell me.</a>
</p><p>
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="xrumer_-_they_re_back!.html">XRumer - they're back!</a></div>
<div class="st2">2007-04-06 <a href="keyword_xrumer.html">xrumer</a> <a href="keyword_spam.html">spam</a></div><br>
So hey, kids, I'm still alive, and now posting from the lovely Caribbean island of Puerto Rico for the foreseeable future.
</p><p>
After the move, and after some confusion on the part of the cable company involving <i>losing my order</i>, I have blessed, blessed broadband
again, without having to cadge the neighbors' WiFi from the rooftop terrace, which would be a great place to work were it not for the tropical
proximity of a horrible huge ball of blazing nuclear explosion hanging over my head, plus the necessity of placing the laptop in a
precarious position on the railing, four floors above concrete, to get good signal.
</p><p>
But now things are good again, and I have 9000 emails to go through (yes, as a guy with a spam filter, I should probably be filtering my spam, but,
well, it's a long story and <i>look, shiny thing!</i>).  And lo! within those 9000 mails were two from hapless forum operators who are getting fed
up with manual despamming.
</p><p>
So sure, I'll be seeing what I can do in that regard, but it piqued my interest in forum spam again.  And so I checked my logs for instances of
XRumer, and wow -- somebody actually <a href="http://kenya.rcbowen.com/talk/viewtopic.php?id=8545">linked my XRumer blog keyword</a> in response to
... a new instance of the XRumer forum bomb.  Dated April 5, as
it so happens.  This one contains the novel text "Also, do you know when XRumer 4.0 Platinum Edition will be released?" and it's posted by AlexMrly.
Google either the phrase or the name, and you'll see a whole lot of forum spam.  Hey, XRumer guys -- thanks!  What we all want is more forum spam!
</p><p>
Now I have that off my chest.  I'm going to reiterate my offer to anybody listening -- I'm going to see what I can do to combat forum spam around
the world, and I'm not charging anything for it.  So far, I'm just in it for the interest, just like email spam in 1999.  Get in touch.  I'll be here.
Well -- I might actually be at the beach.  But I'll be back soon.
</p><p>
Sorry that this post isn't really all that programming-oriented.  I hope to be making that right, in the next couple of days.  Blocking XRumer is
fun, and so easy even a child could do it!  No, seriously: if you want to help me stop XRumer, all I need is your data.
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="mild_cognitive_dissonance.html">Mild cognitive dissonance</a></div>
<div class="st2">2007-04-06 <a href="keyword_xrumer.html">xrumer</a></div><br>
Second post in a day...  Turns out that the WaPo posted on XRumer back in January.
<a href="http://blog.washingtonpost.com/securityfix/2007/01/scary_blogspam_automation_tool_1.html">The article is here, with comments.</a>
Note that the comments are, except for four, <i>all by Russian spammers</i>.  Who are tagging the Washington Post with high-fives
because they've caught the attention of the mainstream.
</p><p>
If that doesn't blow your pretty little mind, I'm not sure what will.  I love this century!
</p><p>
So again: I'll help you block XRumer if you want.  Just <a href="mailto:michael@despammed.com?subject=XRumer%20despamming">drop me a line</a> and
we'll talk.  This ought to be fun.
</p><p>
</p><p>
<br>
</td>
</tr>
<tr>
<td><div class="title"><a href="free_xrumer__honor_among_thieves.html">Free XRUMER?  Honor among thieves</a></div>
<div class="st2">2007-04-25 <a href="keyword_xrumer.html">xrumer</a></div><br>
In the predictability department, one of my forum spam traps just pulled in
an interesting post: yeah, it was posted (presumably) by XRumer and certainly
fits the profile -- but it's advertising a crack of XRumer.
</p><p>
Heh.
</p><p>
"Greate new XRumer4.0 platinum edition and crack DOWNLAUD".
</p><p>
I wondered how long <i>that</i> cash cow would last -- looks like about, what,
November to April?  Actually, it took longer than I expected.
</p><p>
In case you're wondering whether this is a good idea, well, given that you
therefore think spamming is a valid business technique, then: sure, go ahead.
Download a crack from Russians and <i>give</i> them control of your machine.
</p><p>
In related news, I have doubled the number of forum sites I am despamming.
(If you're paying attention, that means, yes, I now have one that isn't my
own site.)  And I decided to try a notion that's really paid off in spades.
</p><p>
See, XRumer uses a vast database of known HTTP relays to post spam.  This
makes it much more difficult for human admins to block by IP -- since a single
spammer may have hundreds of IPs available, how can you block?
</p><p>
Well -- unintended consequence time!  Thanks to the explosion in use of these
proxies, we now have a reliable way to find them out without human intervention
at all.  Count the number of times Google indexes an IP, and you have an
<i>incredibly</i> effective way to determine whether it is on the list of known
proxies used by spammers.  Granted, you have the lag between the time it
becomes a proxy and when Google starts indexing the references to it on forum
posts around the world.  But this one test for spam blocks about 60% or more
of forum spam, sight unseen.
</p><p>
It won't last.  But then again, neither will XRumer, not in its present form.
</p><p>
Just to help you out, I've provided a simple Google hit counter:
<a href="http://www.vivtek.com/google_count">go here and type in any phrase</a>, not just
an IP address, to see how many references to the phrase Google has indexed.
When I've got a little more timeframe behind it, I'll even put in autorepeating
queries of the good ones, with gnuplot graphs to show googlecount over time.
</p><p>
And of course, I'll be putting the code up; it's about ten lines of Perl --
the only reason it's that long is that it caches results in a database so
repeated queries don't pound Google.  Not that Google can't stand the pounding,
but I don't really want a bunch of Perl script threads hanging around waiting
on Net latency.
</p><p>
So, a common refrain lately: more later.
</p><p>
</p><p>
</p><p>
<br>
</td>
</tr>
</table>

</div></td></td></table>

<br><br><br><br>
    <center><img src="/images/black.gif" height=1 width=300><br>
    <Font Size="-1"><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</Font>
</center>


</body>
</html>
